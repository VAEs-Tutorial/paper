{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GMVAE.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPoBxXMYZa91MRJVGUBff/n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VAEs-Tutorial/paper/blob/master/GMVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSGHYVvRbFhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "a9ff3b8c-1b9e-49c6-ad58-3edda8edc66f"
      },
      "source": [
        "!git clone https://github.com/psanch21/VAE-GMVAE.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'VAE-GMVAE'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 217 (delta 3), reused 2 (delta 0), pack-reused 206\u001b[K\n",
            "Receiving objects: 100% (217/217), 14.94 MiB | 31.81 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8K82zut00OU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "bf0b8889-49ec-4554-cd25-967ba4a584a4"
      },
      "source": [
        "!pip install --trusted-host pypi.python.org bunch"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bunch\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/bf/a4cf1779a4ffb4f610903fa08e15d1f4a8a2f4e3353a02afbe097c5bf4a8/bunch-1.0.1.tar.gz\n",
            "Building wheels for collected packages: bunch\n",
            "  Building wheel for bunch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bunch: filename=bunch-1.0.1-cp36-none-any.whl size=7076 sha256=e17e617753d32e460cecb8d8b641975c707802e461fc2498f46225223420eb30\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/0f/19/fbbf81e5764e6d8b74501c4357a88c14c94466ec777c03734c\n",
            "Successfully built bunch\n",
            "Installing collected packages: bunch\n",
            "Successfully installed bunch-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MpS70iU4BDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "fdbccad2-d0ee-4c0c-922f-27db13ffe0bf"
      },
      "source": [
        "!pip install tensorflow==1.7.0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/4a/42ba8d00a50a9fafc88dd5935246ecc64ffe1f6a0258ef535ffb9652140b/tensorflow-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (48.0MB)\n",
            "\u001b[K     |████████████████████████████████| 48.0MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (3.10.0)\n",
            "Collecting tensorboard<1.8.0,>=1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/ec/65d4e8410038ca2a78c09034094403d231228d0ddcae7d470b223456e55d/tensorboard-1.7.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0) (1.30.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.7.0) (47.3.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7.0) (3.2.2)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7.0) (1.0.1)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.8.0,>=1.7.0->tensorflow==1.7.0) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.8.0,>=1.7.0->tensorflow==1.7.0) (3.1.0)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=9ad3886fe18a190233d4ddd87f5ae95798558b8f3a4e8f4951e7bb61ef4760b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.5\n",
            "    Uninstalling bleach-3.1.5:\n",
            "      Successfully uninstalled bleach-3.1.5\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.7.0 tensorflow-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "size-3mzcR0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "214cfa53-0889-4d00-af3f-799fe2d28a05"
      },
      "source": [
        "!python3 /content/VAE-GMVAE/Alg_VAE/VAE_main.py --model_type=0 --dataset_name=MNIST --sigma=0.001 --z_dim=8 --hidden_dim=64 --num_layers=2 --epochs=20 --batch_size=100 --drop_prob=0.3 --l_rate=0.001 --train=1 --results=1 --plot=1 --restore=1 --early_stopping=1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the retry module or similar alternatives.\n",
            "\n",
            " Loading data...\n",
            "WARNING:tensorflow:From /content/VAE-GMVAE/utils/utils.py:93: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "Data loaded.  23 : 22 h\n",
            "Train Data:  (44000, 28, 28, 1)\n",
            "Valid Data:  (11000, 28, 28, 1)\n",
            "Test Data:  (10000, 28, 28, 1)\n",
            "\n",
            "[*] Defining encoder...\n",
            "\n",
            "[*] Layer ( encoder_mean/dense_1/Relu:0 ) output shape: [100, 64]\n",
            "[*] Layer ( encoder_mean/dense_1_dropout/Identity:0 ) output shape: [100, 64]\n",
            "[*] Layer ( encoder_mean/dense_2/BiasAdd:0 ) output shape: [100, 8]\n",
            "\n",
            "[*] Layer ( encoder_var/dense_1/Relu:0 ) output shape: [100, 64]\n",
            "[*] Layer ( encoder_var/dense_1_dropout/Identity:0 ) output shape: [100, 64]\n",
            "[*] Layer ( encoder_var/dense_2/Softplus:0 ) output shape: [100, 8]\n",
            "\n",
            "[*] Reparameterization trick...\n",
            "\n",
            "[*] Defining decoder...\n",
            "\n",
            "[*] Layer ( decoder_mean/dense_1/Relu:0 ) output shape: [100, 64]\n",
            "[*] Layer ( decoder_mean/dense_1_dropout/Identity:0 ) output shape: [100, 64]\n",
            "[*] Layer ( decoder_mean/dense_2/Sigmoid:0 ) output shape: [100, 784]\n",
            "\n",
            "[*] Defining sampling...\n",
            "\n",
            "[*] Layer ( decoder_mean_1/dense_1/Relu:0 ) output shape: [100, 64]\n",
            "[*] Layer ( decoder_mean_1/dense_1_dropout/Identity:0 ) output shape: [100, 64]\n",
            "[*] Layer ( decoder_mean_1/dense_2/Sigmoid:0 ) output shape: [100, 784]\n",
            "[*] Defining Loss Functions and Optimizer...\n",
            "\n",
            "Number of trainable paramters 153056\n",
            "2020-07-09 23:22:25.956982: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "Loading model checkpoint experiments/checkpoint/V_MNIST_0001_8_64_2/-16500 ...\n",
            "\n",
            "Model loaded\n",
            "EPOCHS trained:  10\n",
            "EPOCH:  10\n",
            "100% 440/440 [00:02<00:00, 219.14it/s]\n",
            "100% 110/110 [00:00<00:00, 504.63it/s]\n",
            "TRAIN | Loss:  8207.131  | Recons:  8156.355  | KL:  50.77547  | L2_loss:  26284.572\n",
            "VALID | Loss:  8139.1226  | Recons:  8088.0757  | KL:  51.047073\n",
            "Saving model...\n",
            "Model saved\n",
            "EPOCH:  11\n",
            "100% 440/440 [00:01<00:00, 269.29it/s]\n",
            "100% 110/110 [00:00<00:00, 555.86it/s]\n",
            "TRAIN | Loss:  8183.7227  | Recons:  8132.883  | KL:  50.83939  | L2_loss:  26304.064\n",
            "VALID | Loss:  8131.898  | Recons:  8080.543  | KL:  51.35563\n",
            "EPOCH:  12\n",
            "100% 440/440 [00:01<00:00, 265.46it/s]\n",
            "100% 110/110 [00:00<00:00, 533.68it/s]\n",
            "TRAIN | Loss:  8167.595  | Recons:  8116.7163  | KL:  50.87871  | L2_loss:  26338.926\n",
            "VALID | Loss:  8130.4307  | Recons:  8079.303  | KL:  51.12823\n",
            "EPOCH:  13\n",
            "100% 440/440 [00:01<00:00, 269.29it/s]\n",
            "100% 110/110 [00:00<00:00, 548.41it/s]\n",
            "TRAIN | Loss:  8156.2886  | Recons:  8105.1323  | KL:  51.15609  | L2_loss:  26384.37\n",
            "VALID | Loss:  8138.8555  | Recons:  8088.0923  | KL:  50.762787\n",
            "Patience count:  1\n",
            "EPOCH:  14\n",
            "100% 440/440 [00:01<00:00, 266.77it/s]\n",
            "100% 110/110 [00:00<00:00, 516.94it/s]\n",
            "TRAIN | Loss:  8144.6333  | Recons:  8093.6216  | KL:  51.012188  | L2_loss:  26443.348\n",
            "VALID | Loss:  8129.649  | Recons:  8078.2217  | KL:  51.427185\n",
            "EPOCH:  15\n",
            "100% 440/440 [00:01<00:00, 264.05it/s]\n",
            "100% 110/110 [00:00<00:00, 518.06it/s]\n",
            "TRAIN | Loss:  8134.618  | Recons:  8083.7144  | KL:  50.904076  | L2_loss:  26512.504\n",
            "VALID | Loss:  8118.1  | Recons:  8066.9277  | KL:  51.17183\n",
            "EPOCH:  16\n",
            "100% 440/440 [00:01<00:00, 264.68it/s]\n",
            "100% 110/110 [00:00<00:00, 552.15it/s]\n",
            "TRAIN | Loss:  8125.438  | Recons:  8074.3135  | KL:  51.124786  | L2_loss:  26602.178\n",
            "VALID | Loss:  8123.325  | Recons:  8072.0796  | KL:  51.24643\n",
            "Patience count:  1\n",
            "EPOCH:  17\n",
            "100% 440/440 [00:01<00:00, 268.92it/s]\n",
            "100% 110/110 [00:00<00:00, 554.32it/s]\n",
            "TRAIN | Loss:  8117.197  | Recons:  8066.0864  | KL:  51.110687  | L2_loss:  26696.082\n",
            "VALID | Loss:  8118.7417  | Recons:  8067.559  | KL:  51.18251\n",
            "Patience count:  2\n",
            "EPOCH:  18\n",
            "100% 440/440 [00:01<00:00, 269.54it/s]\n",
            "100% 110/110 [00:00<00:00, 552.42it/s]\n",
            "TRAIN | Loss:  8107.5376  | Recons:  8056.4326  | KL:  51.105663  | L2_loss:  26800.014\n",
            "VALID | Loss:  8120.978  | Recons:  8070.035  | KL:  50.94215\n",
            "Patience count:  3\n",
            "EPOCH:  19\n",
            "100% 440/440 [00:01<00:00, 265.36it/s]\n",
            "100% 110/110 [00:00<00:00, 541.96it/s]\n",
            "TRAIN | Loss:  8101.2295  | Recons:  8050.2314  | KL:  50.99881  | L2_loss:  26921.908\n",
            "VALID | Loss:  8113.0386  | Recons:  8061.2827  | KL:  51.75567\n",
            "EPOCH:  20\n",
            "100% 440/440 [00:01<00:00, 263.65it/s]\n",
            "100% 110/110 [00:00<00:00, 520.61it/s]\n",
            "TRAIN | Loss:  8092.103  | Recons:  8041.0205  | KL:  51.08203  | L2_loss:  27046.504\n",
            "VALID | Loss:  8125.7495  | Recons:  8074.527  | KL:  51.223644\n",
            "Saving model...\n",
            "Model saved\n",
            "Patience count:  1\n",
            "Saving model...\n",
            "Model saved\n",
            "Loading model checkpoint experiments/checkpoint/V_MNIST_0001_8_64_2/-21340 ...\n",
            "\n",
            "Model loaded\n",
            "EPOCHS trained:  21\n",
            "Loading model checkpoint experiments/checkpoint/V_MNIST_0001_8_64_2/-21340 ...\n",
            "\n",
            "Model loaded\n",
            "EPOCHS trained:  21\n",
            "<Figure size 1000x1500 with 25 Axes>\n",
            "<Figure size 1000x1500 with 10 Axes>\n",
            "<Figure size 1000x1500 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}